input {
  kafka {
    client_id => "siae-pm-logstash"
    group_id => "siae-pm-logstash-group"
    topics => ["siae-pm"]
    codec => "json"
    bootstrap_servers => ["kafka01:9092","kafka02:9092","kafka03:9092"]
  }
}

filter {
  date { 
    # Set @timestamp equal to processed date
    match => ["data", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
  }

  mutate {
      # Also update date with processed version
      copy => { "@timestamp" => "data" }
      #Add field to distinguish already processed logs (To batch spark)
      add_field => {"spark_processed" => false}
      # Label applied by Spark ML
      add_field => {"prediction" => -1}
  } 

  mutate{
    convert => {"prediction" => "integer"}
  }
}

output {
  elasticsearch {
    hosts => ["es01:9200", "es02:9200", "es03:9200"]
    index => "siae-pm"
  }
}