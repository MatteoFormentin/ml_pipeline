version: "3.8"
services:
  # ELASTICSEARCH - cannot be scaled due to volume sharing problem
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1
    environment:
      #- "ELASTICSEARCH_USERNAME=elastic"
      #- "ELASTIC_PASSWORD=password"
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      # Configuration file
      - type: bind
        source: ./config/elasticsearch/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      # Data persistence
      - type: volume
        source: es01-data
        target: /usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - cont-net

  # KIBANA
  kib01:
    image: docker.elastic.co/kibana/kibana:7.11.1
    volumes:
      # Configuration file
      - type: bind
        source: ./config/kibana/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - 5601:5601
    networks:
      - cont-net

  # LOGSTASH can be scaled if every istance share the same pipelines
  ls01: 
    image: docker.elastic.co/logstash/logstash:7.11.1
    volumes:
      # Configuration file
      - type: bind
        source: ./config/logstash/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      # Pipeline -> put each pipeline in this folder in a separate file
      - type: bind
        source: ./config/logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - cont-net

  # KAFKA - Requires Zookeper to works and CMAK for gui management (optional)
  zookeeper:
    image: "bitnami/zookeeper:latest"
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - cont-net

  kafka01: # if external access required expose 9092
    image: "bitnami/kafka:latest"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka01-data:/bitnami/kafka
    networks:
      - cont-net

  cmak: # Kafka webui - access with username password as credentials
    image: hlebalbau/kafka-manager:stable
    restart: always
    command:
      - "-Dcmak.zkhosts=zookeeper:2181"
      - "-DbasicAuthentication.enabled=true"
      - "-DbasicAuthentication.username=username"
      - "-DbasicAuthentication.password=password"
    ports:
      - "9000:9000"
    networks:
      - cont-net

  # SPARK
  spark: #Master - only one
    image: docker.io/bitnami/spark:3-debian-10
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080" #only webui accessible from outside

  spark-worker: # Worker: can be scaled undefenitly 
    image: docker.io/bitnami/spark:3-debian-10
    scale: 2 # Number of worker instances
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

volumes:
  es01-data:
    driver: local
  kafka01-data:
    driver: local

networks:
  cont-net:
    driver: bridge